{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT7PRhnMf-kI"
      },
      "source": [
        "# **저시력자를 위한 원화 화폐 분류**\n",
        "---\n",
        "- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n",
        "    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n",
        "    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n",
        "    - 산출물이 잘 나오면 됩니다 : )\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47D2vGDYdCOz"
      },
      "source": [
        "## 0.미션\n",
        "---\n",
        "- **과제 수행 목표**\n",
        "    - 본 과제는 Object Detection 문제입니다.\n",
        "    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n",
        "    - 데이터셋 : money_dataset.zip\n",
        "        1. 데이터셋은 압축 파일로 제공됩니다.\n",
        "        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n",
        "        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n",
        "    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n",
        "    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n",
        "    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n",
        "        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n",
        "        - ex 2) 여러 화폐를 겹치게 하여 촬영\n",
        "---\n",
        "- **Key Point**\n",
        "    1. 모델에 맞는 폴더 구조 확인\n",
        "    2. 이미지 축소 비율에 맞춰 좌표값 변경\n",
        "        - 좌표를 이미지 리사이즈한 비율로 변경\n",
        "    3. 모델에 맞는 정보 추출/형식 변경\n",
        "        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n",
        "    4. 화폐당 하나의 클래스로 변경\n",
        "        - 총 8개 클래스\n",
        "    5. 모델 선택 필요\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZon1K-Ag9be"
      },
      "source": [
        "## 1.환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMgnHN9ZBF05"
      },
      "source": [
        "### (1) 구글 드라이브 연동, 데이터 다운로드\n",
        "---\n",
        "- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCplyiojBFwh",
        "outputId": "b26dbb76-ffba-4e19-f8a5-8cf149ed1898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sUNGwmDxAda",
        "outputId": "09e30676-e3af-44f4-86c3-e9df1d9b5351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8vjv0acBAV4"
      },
      "source": [
        "### (2) 데이터셋 불러오기\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 데이터셋 파일의 압축을 해제하세요.\n",
        "---\n",
        "- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n",
        "    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkSa5ejf8LMe"
      },
      "outputs": [],
      "source": [
        "import zipfile, gdown\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path,os\n",
        "base_path = Path('/content/drive/MyDrive/money_classification')\n",
        "data_path = base_path / Path('dataset')\n",
        "raw_path = base_path/Path('raw')\n",
        "file_name = Path(\"money_dataset.zip\")\n",
        "money_data_path = base_path / file_name\n",
        "\n",
        "# url =\"https://drive.google.com/file/d/1k1tXDK35s6BsMTPGWSl5GVGNoPfC898X/view?usp=drive_link\"\n",
        "# file_name = \"money_dataset.zip\"\n",
        "# output = \"/content/drive/MyDrive/\" + file_name # 변경 가능\n",
        "# if not os.path.exists(output):\n",
        "#     gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8VWtfUPrlXW"
      },
      "outputs": [],
      "source": [
        "url =\"https://drive.google.com/file/d/1k1tXDK35s6BsMTPGWSl5GVGNoPfC898X/view?usp=drive_link\"\n",
        "if not os.path.exists(money_data_path):\n",
        "    gdown.download(url=url, output=money_data_path, quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4cdpkRv86QQ"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n",
        "money_data = zipfile.ZipFile(money_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDAyDRLT9hZS"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 압축 해제\n",
        "money_data.extractall(raw_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyEd-WNIhoSc"
      },
      "source": [
        "## 2.데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P81d6utx-3LY"
      },
      "source": [
        "### (1) 폴더 구조 생성 및 파일 이동\n",
        "---\n",
        "- **세부요구사항**\n",
        "    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n",
        "        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n",
        "---\n",
        "- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_RSEl8guFvd"
      },
      "outputs": [],
      "source": [
        "image_path = data_path / Path(\"images\")\n",
        "label_path = data_path / Path(\"labels\")\n",
        "train_image_path = image_path / Path(\"train\")\n",
        "train_label_path = label_path / Path(\"train\")\n",
        "valid_image_path = image_path / Path(\"valid\")\n",
        "valid_label_path = label_path / Path(\"valid\")\n",
        "train_image_path.mkdir(parents=True,exist_ok=True)\n",
        "train_label_path.mkdir(parents=True,exist_ok=True)\n",
        "valid_image_path.mkdir(parents=True,exist_ok=True)\n",
        "valid_label_path.mkdir(parents=True,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZvKMUq9s58b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import glob, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK6LNJ7oi7-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67477b9-168e-4db1-88d9-e9d921a59d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 348/348 [00:00<00:00, 391.22it/s]\n",
            "100%|██████████| 348/348 [00:00<00:00, 409.01it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 405.25it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 453.35it/s]\n",
            "100%|██████████| 352/352 [00:00<00:00, 359.22it/s]\n",
            "100%|██████████| 352/352 [00:00<00:00, 374.99it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 350.25it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 369.00it/s]\n",
            "100%|██████████| 686/686 [00:02<00:00, 317.72it/s]\n",
            "100%|██████████| 686/686 [00:02<00:00, 312.59it/s]\n",
            "100%|██████████| 172/172 [00:00<00:00, 325.93it/s]\n",
            "100%|██████████| 172/172 [00:00<00:00, 316.04it/s]\n",
            "100%|██████████| 693/693 [00:02<00:00, 318.17it/s]\n",
            "100%|██████████| 693/693 [00:02<00:00, 297.72it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 332.26it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 314.54it/s]\n",
            "100%|██████████| 352/352 [00:01<00:00, 330.97it/s]\n",
            "100%|██████████| 352/352 [00:01<00:00, 337.94it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 342.94it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 311.80it/s]\n",
            "100%|██████████| 352/352 [00:01<00:00, 320.44it/s]\n",
            "100%|██████████| 352/352 [00:01<00:00, 301.14it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 342.79it/s]\n",
            "100%|██████████| 88/88 [00:00<00:00, 361.13it/s]\n",
            "100%|██████████| 693/693 [00:02<00:00, 289.24it/s]\n",
            "100%|██████████| 693/693 [00:02<00:00, 289.65it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 284.01it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 212.39it/s]\n",
            "100%|██████████| 696/696 [00:02<00:00, 281.94it/s]\n",
            "100%|██████████| 696/696 [00:02<00:00, 279.93it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 277.03it/s]\n",
            "100%|██████████| 174/174 [00:00<00:00, 289.10it/s]\n"
          ]
        }
      ],
      "source": [
        "won_list =  [won_path for won_path in raw_path.iterdir()]\n",
        "\n",
        "for path in won_list :\n",
        "    img_file = glob.glob(str(path)+'/*.jpg')\n",
        "    json_file = glob.glob(str(path)+'/*.json')\n",
        "\n",
        "    img_file.sort()\n",
        "    json_file.sort()\n",
        "\n",
        "    img_train, img_val, json_train, json_val = train_test_split(img_file, json_file, random_state=2023, test_size=0.2)\n",
        "    for lis in [img_train, json_train, img_val, json_val] :\n",
        "        for val in tqdm(lis) :\n",
        "            if lis == img_train :\n",
        "                shutil.move(val, train_image_path)\n",
        "            elif lis == json_train :\n",
        "                shutil.move(val, train_label_path)\n",
        "            elif lis == img_val :\n",
        "                shutil.move(val, valid_image_path)\n",
        "            else :\n",
        "                shutil.move(val, valid_label_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pdpNVrYi73N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb1dc49-9beb-4059-ef3f-e5464de3ee72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "total_dir_files= (len(list(valid_label_path.rglob('*.txt'))+list(train_label_path.rglob('*.txt'))))\n",
        "print(total_dir_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx0z9c8bx51m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb10c83-69b6-422a-c348-a2ecde701ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4172it [01:03, 65.29it/s]\n",
            "1046it [00:10, 97.22it/s] \n"
          ]
        }
      ],
      "source": [
        "import os, json\n",
        "label_paths = [train_label_path, valid_label_path]\n",
        "\n",
        "for path in label_paths :\n",
        "    file_list =os.listdir(path)\n",
        "    file_list.sort()\n",
        "    json_list=[val for val in file_list if val.endswith('.json')]\n",
        "    json_to_txt = []\n",
        "    for val in json_list :\n",
        "        json_to_txt.append(val.strip('.json'))\n",
        "    json_to_txt.sort()\n",
        "    for idx, val in tqdm(enumerate(json_list)) :\n",
        "        with open(os.path.join(path,val)) as f:\n",
        "            json_file = json.load(f)\n",
        "\n",
        "        x1, y1 = (json_file['shapes'][0]['points'][0][0])*0.2, (json_file['shapes'][0]['points'][0][1])*0.2\n",
        "        x2, y2 = (json_file['shapes'][0]['points'][1][0])*0.2, (json_file['shapes'][0]['points'][1][1])*0.2\n",
        "        w, h = (json_file['imageWidth'])*0.2, (json_file['imageHeight'])*0.2\n",
        "        label=json_file['shapes'][0]['label']\n",
        "\n",
        "        if label == 'Ten_front' or label=='Ten_back' :\n",
        "            label = 0\n",
        "        elif label == 'Fifty_front' or label=='Fifty_back' :\n",
        "            label = 1\n",
        "        elif label == 'Hundred_front' or label=='Hundred_back' :\n",
        "            label = 2\n",
        "        elif label == 'Five_Hundred_front' or label=='Five_Hundred_back' :\n",
        "            label = 3\n",
        "        elif label == 'Thousand_front' or label=='Thousand_back' :\n",
        "            label = 4\n",
        "        elif label == 'Five_Thousand_front' or label=='Five_Thousand_back' :\n",
        "            label = 5\n",
        "        elif label == 'Ten_Thousand_front' or label=='Ten_Thousand_back' :\n",
        "            label = 6\n",
        "        elif label == 'Fifty_Thousand_front' or label=='Fifty_Thousand_back' :\n",
        "            label = 7\n",
        "        # elif label == 'Ten_front' or label=='Ten_back' :\n",
        "        #     label = 8\n",
        "        # elif label == 'Ten_front' or label=='Ten_back' :\n",
        "        #     label = 9\n",
        "        # else\n",
        "\n",
        "        x_center = ((x1+x2) / 2) /w\n",
        "        y_center = ((y1+y2) / 2) /h\n",
        "        width_norm = (x2-x1)/w\n",
        "        height_norm=(y2-y1)/h\n",
        "\n",
        "        f=open(f'{os.path.join(path,json_to_txt[idx])}.txt','w')\n",
        "        f.write(f'{label} {x_center} {y_center} {width_norm} {height_norm}')\n",
        "        f.close()\n",
        "\n",
        "        os.remove(f'{os.path.join(path,json_to_txt[idx])}.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJgeqXJG1Ml"
      },
      "source": [
        "---\n",
        "- 데이터를 Training set | Validation set으로 분할하세요.\n",
        "    - 예시 : Training과 Validation은 8:2로 분리\n",
        "- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n",
        "    - 예시 : /dataset/images/train, /dataset/labels/train\n",
        "    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "\n",
        "    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "    \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II_hsJ6bKYGn"
      },
      "source": [
        "### (2) json에서 정보 추출\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - json 파일에서 필요한 정보를 추출하세요:\n",
        "        - 위치 정보 : x1, x2, y1, y2\n",
        "        - 박스 정보 : shape_type\n",
        "        - 클래스 정보 : labels\n",
        "    - 화폐당 하나의 클래스로 변경하세요.\n",
        "        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n",
        "        - 화폐의 앞뒷면 구분을 없애주세요.\n",
        "            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n",
        "    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n",
        "        - 사용되는 이미지는 원본에서 1/5로 축소되어 있습니다.\n",
        "        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/5로 줄여주세요.\n",
        "    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n",
        "        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOQeEhApesWR"
      },
      "source": [
        "### (3) 데이터셋 정보가 담긴 파일 생성\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n",
        "        - 학습할 클래스 이름 정보\n",
        "        - 학습할 클래스 수 정보\n",
        "        - Training, Validation 데이터셋 위치 정보\n",
        "---\n",
        "- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n",
        "    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu1iQfQolBhJ"
      },
      "outputs": [],
      "source": [
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1_uOeXcSvv3"
      },
      "outputs": [],
      "source": [
        "won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvMQcHirmSnD"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "\n",
        "temp={'path':str(data_path), 'train':'images/train/', 'val':'images/valid/',\n",
        "      'nc':len(won_list), 'names':won_dict}\n",
        "\n",
        "with open('/content/drive/MyDrive/money_classification/dataset/money.yaml','w') as f:\n",
        "    yaml.dump(temp, f)\n",
        "# print(yaml.dump(temp))\n",
        "\n",
        "# with open('moeny.yaml', 'w') as f:\n",
        "#     yaml.safe_dump(yaml_data, f)\n",
        "\n",
        "# yaml_data = yaml.safe_load(temp)\n",
        "# with open('moeny.yaml', 'w') as f:\n",
        "#     yaml.safe_dump(yaml_data, f)\n",
        "# print(yaml.dump(temp))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F38va1UmHjli"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLHv5YEFHjbs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2mVbZcX6EEb",
        "outputId": "d44e02e0-7428-4750-cc26-c2fbd3703888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-22 05:23:50--  https://raw.githubusercontent.com/DrKAI/CV/main/cat_dog_person.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 423 [text/plain]\n",
            "Saving to: ‘/content/drive/MyDrive/money_classification/dataset/money.yaml’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]     423  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-22 05:23:50 (23.7 MB/s) - ‘/content/drive/MyDrive/money_classification/dataset/money.yaml’ saved [423/423]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "\n",
        "!wget -O /content/drive/MyDrive/money_classification/dataset/money.yaml https://raw.githubusercontent.com/DrKAI/CV/main/cat_dog_person.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIYl5jSH6GzC",
        "outputId": "8e95f096-92d6-47a9-a39e-8786e8aea289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path: /content/datasets/cat_dog_person  # dataset root dir\r\n",
            "train: images/train  # train images (relative to 'path') 128 images\r\n",
            "val: images/train    # val images (relative to 'path') 128 images\r\n",
            "test:  # test images (optional)\r\n",
            "\r\n",
            "# Classes\r\n",
            "nc: 3  # number of classes\r\n",
            "names: ['cat', 'dog', 'person']  # class names\r\n",
            "\r\n",
            "\r\n",
            "# Download script/URL (optional)\r\n",
            "download: https://github.com/DrKAI/CV/raw/main/cat_dog_person.zip\r\n"
          ]
        }
      ],
      "source": [
        "%cat  /content/drive/MyDrive/money_classification/dataset/money.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQZ4pii06HDV",
        "outputId": "4aec7f40-1918-428e-8835-c73eb28bab57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/money_classification/dataset/money.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile  /content/drive/MyDrive/money_classification/dataset/money.yaml\n",
        "\n",
        "\n",
        "train:/content/drive/MyDrive/money_classification/dataset/images/train\n",
        "val: /content/drive/MyDrive/money_classification/dataset/images/valid\n",
        "\n",
        "nc: 8\n",
        "names:\n",
        "  0: '10'\n",
        "  1: '50'\n",
        "  2: '100'\n",
        "  3: '500'\n",
        "  4: '1000'\n",
        "  5: '5000'\n",
        "  6: '10000'\n",
        "  7: '50000'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXkC60fsJhjv",
        "outputId": "fa02dddf-7beb-489f-8c3c-6bc39a1e6c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "train:/content/drive/MyDrive/money_classification/dataset/images/train\n",
            "val: /content/drive/MyDrive/money_classification/dataset/images/valid\n",
            "\n",
            "nc: 8\n",
            "names:\n",
            "  0: '10'\n",
            "  1: '50'\n",
            "  2: '100'\n",
            "  3: '500'\n",
            "  4: '1000'\n",
            "  5: '5000'\n",
            "  6: '10000'\n",
            "  7: '50000'\n"
          ]
        }
      ],
      "source": [
        "%cat  /content/drive/MyDrive/money_classification/dataset/money.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3btFvySXi2dt"
      },
      "source": [
        "## 3.모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQ2gRbTYgLL"
      },
      "source": [
        "### (1) 모델 라이브러리 설치\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TesxD-iZJk9M",
        "outputId": "4d6dcd7e-cf6f-47cc-af94-8d6e3173bd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Biyr9AHkMyNf",
        "outputId": "347fc6fe-6ae7-43f1-e4e1-1c94f4c8f694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15994, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 15994 (delta 18), reused 18 (delta 12), pack-reused 15967\u001b[K\n",
            "Receiving objects: 100% (15994/15994), 14.64 MiB | 737.00 KiB/s, done.\n",
            "Resolving deltas: 100% (10980/10980), done.\n",
            "Collecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.2)\n",
            "Collecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r yolov5/requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.184-py3-none-any.whl (618 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.0/618.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (16.0.6)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.36 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.184\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!pip install -r yolov5/requirements.txt  # install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mHMAspjR6Xp"
      },
      "source": [
        "### (2) 가중치 파일 다운로드\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n",
        "        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSVIqkMLDIOd",
        "outputId": "c3ed1246-45ea-49cb-b236-96e5f7524787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/money_classification/yolov5/pretrained’: No such file or directory\n",
            "/content/drive/MyDrive/money_classification/yolov5/pretrained/yolov5s.pt: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!mkdir /content/drive/MyDrive/money_classification/yolov5/pretrained\n",
        "!wget -O/content/drive/MyDrive/money_classification/yolov5/pretrained/yolov5s.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ########################\n",
        "# # 이 셀부터 코드 작성하세요\n",
        "# ########################\n",
        "# !mkdir /content/yolov5/pretrained\n",
        "# !wget -O /content/yolov5/pretrained/yolov5m.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv_xoCa70u2T",
        "outputId": "24066260-bb35-4302-dd36-bccbcc713ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/yolov5/pretrained’: File exists\n",
            "--2023-09-22 07:38:05--  https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230922%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230922T073805Z&X-Amz-Expires=300&X-Amz-Signature=45f45098103cbe605a65264e73324e7cdcec514928e9b382781fda5be08c04de&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-22 07:38:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/7acc87ed-9e1f-4d4a-8bdc-0912393948df?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230922%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230922T073805Z&X-Amz-Expires=300&X-Amz-Signature=45f45098103cbe605a65264e73324e7cdcec514928e9b382781fda5be08c04de&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42806829 (41M) [application/octet-stream]\n",
            "Saving to: ‘/content/yolov5/pretrained/yolov5m.pt’\n",
            "\n",
            "content/yolov5/pret  42%[=======>            ]  17.53M  7.42MB/s               ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-5lC4mfbwT"
      },
      "source": [
        "### (3) 학습 : train.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n",
        "        - 데이터셋 정보가 담긴 yaml 파일\n",
        "        - 사용하려는 모델 구조에 대한 yaml 파일\n",
        "        - 사용하려는 모델의 가중치 파일\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AYFDMaVfmTK",
        "outputId": "11b9418e-b398-4e2f-d4bd-2efbd06fe766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ invalid check_version(3.1.36, ) requested, please check values.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/pretrained/yolov5s.pt, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/drive/MyDrive/money_classification/dataset/money.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=results, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "WARNING ⚠️ invalid check_version(5.9.5, ) requested, please check values.\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 69.1MB/s]\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from /content/yolov5/pretrained/yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/money_classification/dataset/labels/train... 4172 images, 0 backgrounds, 0 corrupt: 100% 4172/4172 [00:09<00:00, 446.10it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/money_classification/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/money_classification/dataset/labels/valid... 1046 images, 0 backgrounds, 0 corrupt: 100% 1046/1046 [00:03<00:00, 267.51it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/money_classification/dataset/labels/valid.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/results/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/results\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9       3.5G    0.05627    0.02215    0.05287         25        640: 100% 261/261 [00:58<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:11<00:00,  2.97it/s]\n",
            "                   all       1046       1046      0.281      0.803      0.443      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      4.52G    0.03703    0.01191    0.03873         22        640: 100% 261/261 [00:51<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.32it/s]\n",
            "                   all       1046       1046       0.43      0.875       0.65      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      4.52G    0.03351    0.00934    0.02617         29        640: 100% 261/261 [00:52<00:00,  5.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.36it/s]\n",
            "                   all       1046       1046      0.671      0.961      0.767      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      4.52G    0.02775    0.00782    0.02108         22        640: 100% 261/261 [00:52<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.31it/s]\n",
            "                   all       1046       1046      0.703      0.973      0.798      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      4.52G    0.02406   0.007034    0.01954         19        640: 100% 261/261 [00:51<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.71it/s]\n",
            "                   all       1046       1046      0.742      0.866      0.826      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      4.52G    0.02024   0.006398    0.01619         25        640: 100% 261/261 [00:51<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.74it/s]\n",
            "                   all       1046       1046      0.801      0.934      0.891       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      4.52G    0.01761    0.00582    0.01409         30        640: 100% 261/261 [00:50<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.72it/s]\n",
            "                   all       1046       1046      0.914      0.892      0.942       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      4.52G    0.01563   0.005394    0.01218         24        640: 100% 261/261 [00:51<00:00,  5.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:08<00:00,  3.82it/s]\n",
            "                   all       1046       1046      0.925      0.941      0.964      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      4.52G     0.0132    0.00487    0.01023         26        640: 100% 261/261 [00:51<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.60it/s]\n",
            "                   all       1046       1046      0.933      0.967      0.977      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      4.52G    0.01115   0.004523   0.008372         30        640: 100% 261/261 [00:51<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:09<00:00,  3.57it/s]\n",
            "                   all       1046       1046      0.956      0.977      0.988      0.941\n",
            "\n",
            "10 epochs completed in 0.173 hours.\n",
            "Optimizer stripped from runs/train/results/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/results/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/results/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:10<00:00,  3.11it/s]\n",
            "                   all       1046       1046      0.956      0.976      0.988      0.942\n",
            "                    10       1046         88      0.994      0.989       0.99      0.921\n",
            "                    50       1046         88      0.951      0.989      0.989      0.918\n",
            "                   100       1046         88       0.95      0.867      0.975      0.931\n",
            "                   500       1046         88      0.764      0.966      0.969       0.93\n",
            "                  1000       1046        172      0.998          1      0.995      0.945\n",
            "                  5000       1046        174      0.997          1      0.995      0.976\n",
            "                 10000       1046        174      0.997          1      0.995      0.956\n",
            "                 50000       1046        174      0.998          1      0.995      0.956\n",
            "Results saved to \u001b[1mruns/train/results\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!cd yolov5; python train.py \\\n",
        "    --img 640 \\\n",
        "    --epochs 10 \\\n",
        "    --data /content/drive/MyDrive/money_classification/dataset/money.yaml \\\n",
        "    --weights '/content/yolov5/pretrained/yolov5s.pt' \\\n",
        "    --cfg /content/yolov5/models/yolov5s.yaml \\\n",
        "    --name results \\\n",
        "    --exist-ok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2YESAa5fc4M"
      },
      "source": [
        "## 4.탐지 : detect.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n",
        "    - IoU threshold를 0.25 이하로 설정하세요.\n",
        "    - confidence threshold를 0.75 이상으로 설정하세요.\n",
        "---\n",
        "- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n",
        "    - 조건\n",
        "        1. 화폐의 수를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n",
        "        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n",
        "        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rK0ClfTcjEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6263394b-4ee1-4044-970f-4f4da49ae712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/money_classification/dataset/money.yaml, weights=['/content/yolov5/runs/train/results/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.25, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ invalid check_version(5.9.5, ) requested, please check values.\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/money_classification/dataset/labels/valid.cache... 1046 images, 0 backgrounds, 0 corrupt: 100% 1046/1046 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:13<00:00,  2.39it/s]\n",
            "                   all       1046       1046      0.956      0.977      0.988      0.943\n",
            "                    10       1046         88      0.994      0.989       0.99      0.923\n",
            "                    50       1046         88      0.951      0.989      0.988      0.919\n",
            "                   100       1046         88      0.951      0.875      0.975      0.934\n",
            "                   500       1046         88      0.763      0.966      0.969      0.938\n",
            "                  1000       1046        172      0.998          1      0.995      0.946\n",
            "                  5000       1046        174      0.997          1      0.995      0.975\n",
            "                 10000       1046        174      0.997          1      0.995      0.956\n",
            "                 50000       1046        174      0.998          1      0.995      0.956\n",
            "Speed: 0.1ms pre-process, 4.6ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!cd yolov5; python val.py \\\n",
        "    --weights /content/yolov5/runs/train/results/weights/best.pt \\\n",
        "    --data /content/drive/MyDrive/money_classification/dataset/money.yaml \\\n",
        "    --img 640 \\\n",
        "    --iou 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfijOywsLi8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3564799b-c1a6-4e5c-c603-f8fa6303e130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/results/weights/best.pt'], source=/content/yolov5/data/images/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.75, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "WARNING ⚠️ invalid check_version(5.9.5, ) requested, please check values.\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/6 /content/yolov5/data/images/all.jpg: 608x640 1 10, 1 50, 44.6ms\n",
            "image 2/6 /content/yolov5/data/images/back.jpg: 640x480 2 50s, 1 1000, 44.3ms\n",
            "image 3/6 /content/yolov5/data/images/five_hund.jpg: 640x480 1 500, 8.6ms\n",
            "image 4/6 /content/yolov5/data/images/front.jpg: 640x480 1 500, 1 1000, 8.6ms\n",
            "image 5/6 /content/yolov5/data/images/hun.jpg: 512x640 (no detections), 43.8ms\n",
            "image 6/6 /content/yolov5/data/images/thous.jpg: 640x480 1 1000, 8.7ms\n",
            "Speed: 0.6ms pre-process, 26.4ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!cd yolov5; python detect.py \\\n",
        "    --weights /content/yolov5/runs/train/results/weights/best.pt \\\n",
        "    --source /content/yolov5/data/images/ \\\n",
        "    --img 640 \\\n",
        "    --iou 0.25 \\\n",
        "    --conf-thres 0.75 \\\n",
        "    --line-thickness 2 \\\n",
        "    --exist-ok"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drxRW55zrpyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}